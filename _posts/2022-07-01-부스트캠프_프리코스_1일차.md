# 딥러닝 Basic

- 딥러닝 능력
  1. 구현 능력(텐서플로우, 파이토치)
  2. 수학 능력(선형 대수, 확률론)
  3. 많은 양의 최신 논문 데이터 공부

## Introduction

<img src="C:\Users\wlsgy\SonJinHYo.github.io\_images\2022-07-01-부스트캠프_프리코스_1일차\image-20220701105636724.png" alt="image-20220701105636724" style="zoom:67%;" />

- 인공지능 : 인간의 행위를 모방
  - 머신러닝 : 데이터 가공 접근방법
    - 딥러닝 : 뉴럴 네트웨크

### 딥러닝의 주요 구성요소

**어떠한 연구대상을 보았을 때 고려해보야할 요소**

1. 데이터 :  학습시킬수 있는 모델에 대한 데이터

   - 해결가능한 문제 타입에 의존하는 데이터

2. 모델 : 데이터를 어떻게 변화시킬지

   - 같은 데이터라도 어떤 모델을 적용하는가에 따라 다양한 오류와 결과를 불러온다

     <img src="C:\Users\wlsgy\SonJinHYo.github.io\_images\2022-07-01-부스트캠프_프리코스_1일차\image-20220701111145477.png" alt="image-20220701111145477" style="zoom:67%;" />

3. loss function : 성취하고자 하는 결과와의 편차

   <img src="C:\Users\wlsgy\SonJinHYo.github.io\_images\2022-07-01-부스트캠프_프리코스_1일차\image-20220701111255643.png" alt="image-20220701111255643" style="zoom:80%;" />

- 일반적으로 loss값을 줄이는 방향으로 모델과 loss function을 조정해가지만 **무조건적으로** loss값을 줄이는 게 목표는 아니다
4. 알고리즘 : 손실을 최소화할수 있는 파라미터 조정을 위한

   <img src="C:\Users\wlsgy\SonJinHYo.github.io\_images\2022-07-01-부스트캠프_프리코스_1일차\image-20220701111502646.png" alt="image-20220701111502646" style="zoom: 67%;" />





# Historical Review

## AlexNey - 2012

이전부터 있어온 이미지영상처리에 대한 대회에서 2012년배 대회 때 AlexNet을 이용한 딥러닝이 1등을 한 이후로 계속해서 딥러닝이 1등을 해오고 이전 알고리즘들과의 격차가 꾸준히 벌어짐

<img src="C:\Users\wlsgy\SonJinHYo.github.io\_images\2022-07-01-부스트캠프_프리코스_1일차\image-20220701112239519.png" alt="image-20220701112239519" style="zoom:67%;" />

## DNQ - 2013

![image-20220701112248837](C:\Users\wlsgy\SonJinHYo.github.io\_images\2022-07-01-부스트캠프_프리코스_1일차\image-20220701112248837.png)

## Encoder/Decoder, Adam - 2014

Encoder/Decoder - 언어 번역을 위한 딥러닝 모델

<img src="C:\Users\wlsgy\SonJinHYo.github.io\_images\2022-07-01-부스트캠프_프리코스_1일차\image-20220701112141886.png" alt="image-20220701112141886" style="zoom:67%;" />

Adam Optimizer - 모델_아담의 결과가 가장 잘나오기 때문에 아담을 주로 쓰게됨

<img src="C:\Users\wlsgy\SonJinHYo.github.io\_images\2022-07-01-부스트캠프_프리코스_1일차\image-20220701112228602.png" alt="image-20220701112228602" style="zoom:67%;" />

## GAN, ResNet - 2015

**GAN - Generative Adversarial Network**

<img src="C:\Users\wlsgy\SonJinHYo.github.io\_images\2022-07-01-부스트캠프_프리코스_1일차\image-20220701112511084.png" alt="image-20220701112511084" style="zoom: 80%;" />

ResNet - Residual Networks

<img src="C:\Users\wlsgy\SonJinHYo.github.io\_images\2022-07-01-부스트캠프_프리코스_1일차\image-20220701112626654.png" alt="image-20220701112626654" style="zoom:80%;" />

- 딥러닝이 현재의 딥러닝의 구색을 갖추게 된 시점. 네트워크를 쌓아가는 것이 딥러닝인데 너무 많이 쌓이면 안좋다. 하지만 이 시점부터 많은 데이터를 쌓을 수 있게 된다.



## Transformer - 2017

<img src="C:\Users\wlsgy\SonJinHYo.github.io\_images\2022-07-01-부스트캠프_프리코스_1일차\image-20220701112858234.png" alt="image-20220701112858234" style="zoom:80%;" />

- 이전 딥러닝 방법론을 대부분 대체한 모델



## BERT (fine-turned NLP models) - 2018

**B**idirectional **E**ncoder **R**epresentations **T**ransformers

<img src="C:\Users\wlsgy\SonJinHYo.github.io\_images\2022-07-01-부스트캠프_프리코스_1일차\image-20220701113105364.png" alt="image-20220701113105364" style="zoom:67%;" />



## BIG Language Models - 2019

<img src="C:\Users\wlsgy\SonJinHYo.github.io\_images\2022-07-01-부스트캠프_프리코스_1일차\image-20220701113138698.png" alt="image-20220701113138698" style="zoom:67%;" />



## Self Supervised Learning  - 2020

라벨이 없는 분류데이터도 학습에 활용할 수 있도록 만듬

<img src="C:\Users\wlsgy\SonJinHYo.github.io\_images\2022-07-01-부스트캠프_프리코스_1일차\image-20220701113358881.png" alt="image-20220701113358881" style="zoom:80%;" />
